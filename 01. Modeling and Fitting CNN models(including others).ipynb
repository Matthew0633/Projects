{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 images belonging to 2 classes.\n",
      "Found 399 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# [load_data]\n",
    "TRAIN_DIR = 'videos/images/1/train/'\n",
    "TEST_DIR = 'videos/images/1/train/'\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "IM_WIDTH = 500  # generated img size \n",
    "IM_HEIGHT = 275\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    TRAIN_DIR,\n",
    "                    target_size = (IM_WIDTH, IM_HEIGHT),\n",
    "                    batch_size = BATCH_SIZE\n",
    "                    class_mode = 'categorical', yt\n",
    "                    shuffle = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                    TEST_DIR,\n",
    "                    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num = len(train_generator.class_indices) #하위폴더명을 class로 정의해줌\n",
    "class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danger', 'safe']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_labels = list(train_generator.class_indices.keys()) # keys(): class_names, items() : counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Modeling]\n",
    "\n",
    "def modeling_CNN():\n",
    "    kernel_size = (3,3)\n",
    "    pool_size= (2,2)\n",
    "    first_filters = 32\n",
    "    second_filters = 64\n",
    "    third_filters = 128\n",
    "\n",
    "    dropout_conv = 0.3\n",
    "    dropout_dense = 0.3\n",
    "\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=first_filters, kernel_size=5, activation=tf.nn.relu, padding='SAME',input_shape=(IM_WIDTH, IM_HEIGHT,3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dropout(dropout_conv))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(filters=second_filters, kernel_size=5, activation=tf.nn.relu, padding='SAME',input_shape=(IM_WIDTH, IM_HEIGHT,3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dropout(dropout_conv1))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(filters=third_filters, kernel_size=5, activation=tf.nn.relu, padding='SAME',input_shape=(IM_WIDTH, IM_HEIGHT,3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dropout(dropout_conv))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=5, activation=tf.nn.relu, padding='SAME',input_shape=(IM_WIDTH, IM_HEIGHT,3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dropout(dropout_conv))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(filters=first_filters, kernel_size=5, activation=tf.nn.relu, padding='SAME',input_shape=(IM_WIDTH, IM_HEIGHT,3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dropout(dropout_conv))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "\n",
    "    model.add(keras.layers.Dense(1024,activation=tf.nn.relu)) #weight 1024개를 만들어줘라 선형회귀 실행(너무 많으면 과적합)\n",
    "    model.add(keras.layers.Dropout(dropout_dense1))\n",
    "    model.add(keras.layers.Dense(class_num, activation='softmax')) \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "# ResNet50\n",
    "rn50_conv_layers = keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, \n",
    "                                                        input_shape=(IM_WIDTH, IM_HEIGHT, 3))\n",
    "# VGGNet19\n",
    "VGG19_conv_layers = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_tensor=None,\n",
    "                                                 input_shape=(IM_WIDTH, IM_HEIGHT, 3), pooling=None, classes=2)\n",
    "# InceptionResNet19\n",
    "IRNV2_conv_layers = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=None,\n",
    "                                                             input_shape=(IM_WIDTH, IM_HEIGHT, 3), pooling=None, classes=2)\n",
    "# DenseNet\n",
    "DN_conv_layers = keras.applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_tensor=None,\n",
    "                                                          input_shape=(IM_WIDTH,IM_HEIGHT,3), pooling=None, classes=2)\n",
    "# NasNet\n",
    "NN_conv_layers = keras.applications.nasnet.NASNetLarge(include_top=False, weights='imagenet', \n",
    "                                                        input_shape=(IM_WIDTH, IM_HEIGHT, 3), pooling=None, classes=2)\n",
    "# MobileNetV2\n",
    "MNV2_conv_layers = keras.applications.mobilenet_v2.MobileNetV2(alpha=1.0, include_top=False, weights='imagenet', input_tensor=None,\n",
    "                                                              input_shape=(IM_WIDTH,IM_HEIGHT,3),  pooling=None, classes=2)\n",
    "def modeling_keras_apps_models(conv_layers):\n",
    "    dropout_dense = 0.1\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(conv_layers)\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(dropout_dense))\n",
    "    model.add(keras.layers.Dense(class_num, activation='softmax'))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 400, 300, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 200, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 200, 150, 64)      51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 100, 75, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 75, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 75, 128)      204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 50, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 50, 38, 64)        204864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 19, 32)        51232     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 13, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              4260864   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 4,777,634\n",
      "Trainable params: 4,777,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modeling_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jasonpark\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 13, 10, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 266240)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              272630784 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 296,220,546\n",
      "Trainable params: 296,167,426\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modeling_keras_apps_models(rn50_conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using all models\n",
    "model = modeling_CNN()\n",
    "# model = modeling_keras_apps_models(rn50_conv_layers)\n",
    "# model = modeling_keras_apps_models(VGG19_conv_layers)\n",
    "# model = modeling_keras_apps_models(IRNV2_conv_layers)\n",
    "# model = modeling_keras_apps_models(DN_conv_layers)\n",
    "# model = modeling_keras_apps_models(MNV2_conv_layers)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = keras.optimizers.Adam(lr = LR), metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = (train_generator.samples / train_generator.batch_size) ,\n",
    "      epochs = 10,\n",
    "      validation_data = test_generator,\n",
    "      validation_steps = test_generator.samples / test_generator.batch_size,\n",
    "      verbose = 1)\n",
    "\n",
    "# acc, loss visualization (for 'epoch' optimization)\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "x = range(len(acc))\n",
    " \n",
    "plt.plot(x, acc, 'b', label='accuracy')\n",
    "plt.plot(x, loss, 'r', label='loss')\n",
    "plt.title('accuracy and loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction (Model Performatnce Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Prediction]\n",
    "\n",
    "# load test_data\n",
    "files = [\n",
    "    'videos/images/1/train/test1.jpg',\n",
    "    'videos/images/1/train/test2.jpg',\n",
    "    'videos/images/1/train/test3.jpg',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    image=load_img(file)\n",
    "    display(image)\n",
    "    image_resize=load_img(file, target_size=(IM_WIDTH,IM_HEIGHT))\n",
    "    image_arr_dm3 = img_to_array(image_resize)\n",
    "    image_arr_dm4 = image_arr_dm3.reshape((1,IM_WIDTH,IM_HEIGHT,3))\n",
    "    \n",
    "    yhat=model.predict(image_arr_dm4)\n",
    "    idx=np.argmax(yhat[0])\n",
    "    print('%s (%.2f%%)' % (custom_labels[idx], yhat[0][idx]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model('Baby_door.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model('Baby_eat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model('Baby_fall.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model('Baby_kitchen.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
